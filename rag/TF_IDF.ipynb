{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e714475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Simple TF-IDF Search Demo\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from utils import get_doc_info\n",
    "\n",
    "print(\"üîç TF-IDF Search Demo\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load documents from techcorp-docs\n",
    "docs, doc_paths = get_doc_info()\n",
    "\n",
    "# Create TF-IDF matrix\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(docs)\n",
    "\n",
    "# Example searches\n",
    "queries = [\"remote work policy\", \"health insurance benefits\", \"pet policy dogs\"]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"üîé Searching for: '{query}'\")\n",
    "    \n",
    "    # Transform query to TF-IDF\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    \n",
    "    # Get top results\n",
    "    top_indices = similarities.argsort()[-3:][::-1]\n",
    "    \n",
    "    print(\"Results:\")\n",
    "    for i, idx in enumerate(top_indices, 1):\n",
    "        # Show only document path and score\n",
    "        doc_name = doc_paths[idx].split('/')[-1]  # Just the filename\n",
    "        print(f\"  {i}. Score: {similarities[idx]:.4f} - {doc_name}\")\n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ TF-IDF search completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f08cbbb",
   "metadata": {},
   "source": [
    "BM25 search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f8057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Simple BM25 Search Demo\n",
    "\"\"\"\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "import re\n",
    "from utils import get_doc_info\n",
    "\n",
    "print(\"üîç BM25 Search Demo\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load documents from techcorp-docs\n",
    "docs, doc_paths = get_doc_info()\n",
    "print(f\"üìö Loaded {len(docs)} documents\\n\")\n",
    "\n",
    "# Tokenize documents\n",
    "tokenized_docs = [re.sub(r'[^a-zA-Z\\s]', '', doc.lower()).split() for doc in docs]\n",
    "\n",
    "# Create BM25 index\n",
    "bm25 = BM25Okapi(tokenized_docs)\n",
    "\n",
    "# Example searches\n",
    "queries = [\"remote work policy\", \"health insurance benefits\", \"pet policy dogs\"]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"üîé Searching for: '{query}'\")\n",
    "    \n",
    "    # Tokenize query\n",
    "    tokenized_query = re.sub(r'[^a-zA-Z\\s]', '', query.lower()).split()\n",
    "    \n",
    "    # Get BM25 scores\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    \n",
    "    # Get top results\n",
    "    top_indices = scores.argsort()[-3:][::-1]\n",
    "    \n",
    "    print(\"Results:\")\n",
    "    for i, idx in enumerate(top_indices, 1):\n",
    "        # Show only document path and score\n",
    "        doc_name = doc_paths[idx].split('/')[-1]  # Just the filename\n",
    "        print(f\"  {i}. Score: {scores[idx]:.4f} - {doc_name}\")\n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ BM25 search completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a70784",
   "metadata": {},
   "source": [
    "Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe995caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Hybrid Search Implementation\n",
    "Combines TF-IDF and BM25 scores with different weights\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rank_bm25 import BM25Okapi\n",
    "import re\n",
    "from utils import get_doc_info\n",
    "\n",
    "def hybrid_search(query, docs, tfidf_weight=0.3, bm25_weight=0.7):\n",
    "    \"\"\"Combine TF-IDF and BM25 scores with weights\"\"\"\n",
    "    \n",
    "    # TF-IDF scores\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(docs)\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    tfidf_scores = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    \n",
    "    # BM25 scores\n",
    "    tokenized_docs = [re.sub(r'[^a-zA-Z\\s]', '', doc.lower()).split() for doc in docs]\n",
    "    bm25 = BM25Okapi(tokenized_docs)\n",
    "    tokenized_query = re.sub(r'[^a-zA-Z\\s]', '', query.lower()).split()\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    \n",
    "    # Normalize BM25 scores to 0-1 range for fair comparison\n",
    "    if bm25_scores.max() > 0:\n",
    "        bm25_scores = bm25_scores / bm25_scores.max()\n",
    "    \n",
    "    # Combine scores\n",
    "    hybrid_scores = tfidf_weight * tfidf_scores + bm25_weight * bm25_scores\n",
    "    \n",
    "    return tfidf_scores, bm25_scores, hybrid_scores\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate hybrid search\"\"\"\n",
    "    print(\"üîç Hybrid Search Demo\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Load documents from techcorp-docs\n",
    "    docs, doc_paths = get_doc_info()\n",
    "    \n",
    "    # Test different weight combinations\n",
    "    query = \"remote work policy\"\n",
    "    print(f\"üîé Testing query: '{query}'\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    weight_combinations = [\n",
    "        (0.5, 0.5, \"Equal weights\"),\n",
    "        (0.3, 0.7, \"BM25 favored\"),\n",
    "        (0.7, 0.3, \"TF-IDF favored\")\n",
    "    ]\n",
    "    \n",
    "    for tfidf_w, bm25_w, description in weight_combinations:\n",
    "        print(f\"\\nüìä {description} (TF-IDF: {tfidf_w}, BM25: {bm25_w})\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        tfidf_scores, bm25_scores, hybrid_scores = hybrid_search(query, docs, tfidf_w, bm25_w)\n",
    "        \n",
    "        # Get top 3 results\n",
    "        top_indices = hybrid_scores.argsort()[-3:][::-1]\n",
    "        \n",
    "        print(\"Top 3 results:\")\n",
    "        for i, idx in enumerate(top_indices, 1):\n",
    "            # Show only document path and score\n",
    "            doc_name = doc_paths[idx].split('/')[-1]  # Just the filename\n",
    "            print(f\"  {i}. Score: {hybrid_scores[idx]:.4f} - {doc_name}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Hybrid search analysis completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0899081a",
   "metadata": {},
   "source": [
    "compare method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Compare Search Methods\n",
    "Demonstrates the differences between grep, TF-IDF, and BM25\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rank_bm25 import BM25Okapi\n",
    "from utils import get_doc_info\n",
    "\n",
    "def grep_search(query, documents):\n",
    "    \"\"\"Simple grep-like search - exact keyword matching\"\"\"\n",
    "    results = []\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    for i, doc in enumerate(documents):\n",
    "        if query_lower in doc.lower():\n",
    "            count = doc.lower().count(query_lower)\n",
    "            results.append((i, count))\n",
    "    \n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results\n",
    "\n",
    "def tfidf_search(query, documents):\n",
    "    \"\"\"TF-IDF search using sklearn\"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    \n",
    "    results = [(i, similarities[i]) for i in range(len(documents))]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results\n",
    "\n",
    "def bm25_search(query, documents):\n",
    "    \"\"\"BM25 search using rank_bm25\"\"\"\n",
    "    tokenized_docs = [re.sub(r'[^a-zA-Z\\s]', '', doc.lower()).split() for doc in documents]\n",
    "    bm25 = BM25Okapi(tokenized_docs)\n",
    "    tokenized_query = re.sub(r'[^a-zA-Z\\s]', '', query.lower()).split()\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    \n",
    "    results = [(i, scores[i]) for i in range(len(documents))]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to compare search methods\"\"\"\n",
    "    print(\"üîç Search Methods Comparison\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load documents from techcorp-docs\n",
    "    docs, doc_paths = get_doc_info()\n",
    "    print()\n",
    "    \n",
    "    # Test query\n",
    "    query = \"remote work policy\"\n",
    "    print(f\"üîé Testing query: '{query}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Grep search\n",
    "    print(\"\\n1Ô∏è‚É£ GREP SEARCH (Exact keyword matching):\")\n",
    "    grep_results = grep_search(query, docs)\n",
    "    for rank, (doc_idx, count) in enumerate(grep_results[:3], 1):\n",
    "        print(f\"  {rank}. Doc {doc_idx+1}: {count} matches - {docs[doc_idx][:80]}...\")\n",
    "    \n",
    "    # TF-IDF search\n",
    "    print(\"\\n2Ô∏è‚É£ TF-IDF SEARCH (Term frequency-inverse document frequency):\")\n",
    "    tfidf_results = tfidf_search(query, docs)\n",
    "    for rank, (doc_idx, score) in enumerate(tfidf_results[:3], 1):\n",
    "        print(f\"  {rank}. Doc {doc_idx+1}: Score {score:.4f} - {docs[doc_idx][:80]}...\")\n",
    "    \n",
    "    # BM25 search\n",
    "    print(\"\\n3Ô∏è‚É£ BM25 SEARCH (Okapi BM25 with document length normalization):\")\n",
    "    bm25_results = bm25_search(query, docs)\n",
    "    for rank, (doc_idx, score) in enumerate(bm25_results[:3], 1):\n",
    "        print(f\"  {rank}. Doc {doc_idx+1}: Score {score:.4f} - {docs[doc_idx][:80]}...\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Search methods comparison completed!\")\n",
    "    print(\"\\nüí° Key Insights:\")\n",
    "    print(\"- Grep: Simple exact matching, good for specific terms\")\n",
    "    print(\"- TF-IDF: Balances term frequency with document rarity\")\n",
    "    print(\"- BM25: Advanced ranking with document length normalization\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
